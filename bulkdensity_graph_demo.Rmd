---
title: "Bulk Density in the National Cooperative Soil Survey Characterization Database"
author: "Andrew G. Brown"
date: "10/29/2020" 
output: html_document
---
```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE, echo = FALSE)
```
 
## Soil bulk density is fundamental to understanding soils.

There is a great deal more information on the topics referenced in this document in the [National Soil Survey Handbook (NSSH)](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/ref/?cid=nrcs142p2_054242), 

Soil particle size distribution, mineralogy, grain packing, soil depth, and organic matter content are among the major properties affecting the bulk densities we observe in soil materials (NSSH, parts 618.32 "Rock fragments in the soil", 618.44 "Organic Matter", 618.45 "Parent Material, Kind, Modifier, and Origin")

### Soil Materials

In the USDA system we have mineral and organic soil materials (Keys to Soil Taxonomy, 12th edition, p. 3). 

_Mineral soil materials_ are particles passing a 2.0 mm sieve with carbon content (by weight) less than a threshold. The definition in  takes into account water saturation of the soil and clay content to the threshold. _Organic soil materials_ are defined as materials exceeding the carbon thresholds for mineral soil materials.

### The "Whole Soil" basis

The _Whole Soil_ is the basis we report many measurements on for NCSS products -- notably available water capacities, water retention values, and the like. But any measurement that is made on an oven-dry soil mass basis ultimately is corrected to the Whole Soil basis for broader use. This is to include effects of larger rock/wood/non-soil materials that occupy volume but lack the bulk characteristics of soil materials. 

Soil materials are often the fundamental "object" of our study, but the content and distribution of larger fragment materials within the soil body is very important to soil classification and interpretations.

### Fundamental definitions

#### Particle density

The solid particles that comprise the Whole Soil are classified based on whether they pass a 2 mm sieve. This naturally provides distinction for materials that are granular in nature. The material that passes the sieve is the _fine-earth fraction_ and the material retained is the _coarse fraction_. In principle, a particle in a soil could be a mineral grain, an organic fiber, a microbe, a piece of gravel, a tree trunk, a boulder, etc.

Particles are single "pieces" of coherent/cemented material. The process of separating particle from one another systematically based on size and related physical characteristics is called _particle size analysis_. 

We define the density of our broadly-defined "particle" $D_{p}$ as follows:

$$D_{p} = \frac{m_{particle}}{V_{particle}}$$

Assumptions are commonly used for particle density. A common $D_{p}$ figure for silicates is $2.65~g/cm^3$. In NASIS at the individual _Pedon_ and map unit _Component_ level we have fields and calculations for particle density. We also have the ability to measure it in the lab for soils or their separates.

#### Bulk density

The "bulk" density of a sample integrates all of the masses of particles over a volume of Whole Soil. When coarse particles (fragments greater than 2 mm diameter) are present in that volume, conventionally they are negated from the sample volume to calculate _soil bulk density_.

$$D_{b, soil} = \frac{m_{soil,~oven~dry}}{V_{soil}} = \frac{m_{soil,~oven~dry}}{V_{sample} - \frac{m_{fragments}}{D_{p,fragments}}}$$

When one considers that most soil analyses are reported on an oven-dry mass basis (e.g. $mg/kg$), bulk density one of two critical scaling factors to relate to the "Whole Soil" reference condition. 

The second is fragments. The volume of fragments in the layer being summarized may be appreciably affecting soil functions such as water movement or heat transfer, so they are important to recognize despite not being "soil materials." 

#### Soil v.s. Non-soil

Knowing where in the profile a bulk density sample came from, whether it was sieved, whether there were volumetric estimates of fragments, and the moisture state (e.g. field moist, oven-dry, X tension) is essential to interpretation of bulk density values for soils. 

If water or fragment contents are not known, they are not known. This makes it somewhat harder to interpret bulk density "data" (which is always a calculation of some sort) at face value -- you do not know what materials the mass refers to. 

Efforts should be made to categorize data sets and provide options to support meta-correlation involving _similar_ parameters when  constituent measurements for bulk density are missing or unreliable. 

### Rock fragment volume estimates

See NSSH part 618.32 "Fragments in the Soil"

For an individual sample, we will get sieve separates for the coarse fraction from the lab, but we really lean on the field observations of these properties. Mass basis measurements of fragments (accurate) are be converted to _meaningful_ volume estimates by dividing by $D_p$. With a standard sieve and a rugged scale, one can relatively readily do field measurements of fragments up to 76 mm.

For larger fragments, if a large proportion are near or greater than 76mm, you would may need to sieve several hundred kilograms or more of sample to get a "representative" weight per volume -- so commonly this is done by visual estimate (like a routine profile description).

 - The 2 - 20 mm and 20 - 76 mm fractions are sieved and weighed in the field at sampling time. The field measurements and estimations are provided to the lab as metadata, ultimately paired by `labsampnum`. 
 
 - The larger fractions are stored in the NASIS _Pedon_ object. _Pedon Horizon Fragments_ holds weight or volume $\%$ measures as needed; volume $\%$ is what is conventionally reported in our maps.

### Calculate organic carbon stocks with bulk density

A Carbon pool, or stock, is a value with units of mass per area. It is an excellent applied example of the effects of soil bulk density on the types of measurements we make on soils. 

$C_p$ is the sum of organic carbon contents $C_i$ ($\%~by~mass$) multiplied by bulk density $D_{b, i}$ ($kg/m^3$) multiplied by layer thickness $L_i$ ($m$). These can be scaled based on $V_{fragments, i}$, the ratio of the layer volume occupied by fragments to the total volume of the layer. 

The result is in units of  $kg/m^2$; where the 1-D definition is aggregation soil length over $n$ layers; so "stocks" are conventionally reported over a specific interval (e.g. 0 to 100 cm).

$$Cp = \sum_{i=1}^{n}\left(\frac{C_i}{100} * D_{b, soil, i} * L_{i} * V_{fragments, i}\right)$$

The most appropriate "total fragment volume" (accounting for all size classes) for a layer often is not the same as what was observed in an individual sieved core or clod sample at the lab. However, the precision of e.g. visual estimates is certainly not as reliable as the portions measured in the lab. There is a balance that needs to be struck based on applications of an analysis or their scope.

## Analyte and Method Metadata Wrangling

There is more to this than oven-dry bulk density and sieving fragments, though.

The `lab_analyte` table is found in Soil Data Access (SDA), as well as the various lab data snapshots. SDA is the web API for accessing most of the public data available from the NCSS. This table contains definitions of the analytes (physical and chemical measurements) used in the National Cooperative Soil Survey Characterization Database Snapshot.

The `lab_method_code` table indexes the specific procedures used to measure analytes, abbreviation codes, and references. There is not a 1:1 relationship between analytes and methods. In some cases, older methods have become obsolete and replaced with new method codes that measure the same analyte, so there are many method codes for one analyte. Some methods measure multiple analytes. Some analytes are more specific and have only a single method code in use. Further, there are derivative analytes that are based on calculations using other analytes.

There is a significant amount of information and metadata stored in the collective group of databases that feed into NASIS (the National Soil Information System).

In NASIS, there are still some important linkages to various internal databases held together by dedicated software and manual interventions. Recognizing important linkages within the database currently requires some insider knowledge. It would be good to make some of these linkages more explicit, transparent and portable. 

New delivery methods for the laboratory characterization data are a work in progress by the USDA-NRCS Soil Survey Staff. This effort would be greatly enhanced by collaboration with the Soil Ontology group. 

```{r}
library(soilDB)
library(ggplot2)
library(data.tree)
library(networkD3)

methods <- SDA_query("SELECT DISTINCT procedure_key, proced_abbrev, requested_anal_name, 
                     proced_name, proced_code, proced_desc FROM lab_method_code")
# clean whitespace
methods$requested_anal_name <- trimws(methods$requested_anal_name)

# extract method group if available (Bulk Density, ....) <- before the comma
methods$method_group <- as.character(lapply(strsplit(methods$requested_anal_name, ",", TRUE), function(x) x[[1]]))

# build data.tree path: [root] -> [method group] -> [analysis name] -> [procedure name] -> [procedure code + (description)]
methods$path <- sprintf("%s|%s|%s", 'NCSS Lab Methods',  methods$method_group, methods$proced_code)

# init data.tree from path, attaching additional columns to leaves
res <- as.Node(methods, pathName = 'path', pathDelimiter = '|')

par(mar=c(0,0,0,0))
useRtreeList <- ToListExplicit(res, unname = TRUE)
radialNetwork(useRtreeList, fontSize = 18)

## salvage relationships by reverse engineering from physical/chemical properties tables
phys_names <- colnames(SDA_query("SELECT TOP(1) * from lab_physical_properties"))
idx <- grep("method$", phys_names)
phys_measure_names <- phys_names[idx - 1]
phys_measure_methods <- phys_names[idx]
# nb: check  "estimated_om_plus_mineral"         "fiber_analysis_method"

# focus just on Db
db.idx <- grep("bulk_de|bd_", phys_measure_methods)
db_measur_cols <- phys_measure_names[db.idx]
db_method_cols <- phys_measure_methods[db.idx]

if (!file.exists("db_data_methods_table.rda")) {
  # identify method codes referenced for each "data" column
  db_data_methods_table <- data.table::rbindlist(lapply(db_method_cols, function(x) {
    SDA_query(sprintf("SELECT %s FROM lab_physical_properties WHERE %s != ''", x, x))
  }), fill = TRUE)
  save(db_data_methods_table, file = "db_data_methods_table.rda")
} else {
  load("db_data_methods_table.rda")
}
db_data_methods <- apply(as.data.frame(db_data_methods_table), 2, unique)

# lapply(db_data_methods, function(x) db_methods[na.omit(match(x, db_methods$proced_code)),])

# get the analyte table
analytes <- SDA_query("SELECT * from lab_analyte")

# filter for bulk density related analytes
db_analytes <- subset(analytes, grepl("db_", analyte_abbrev))

# change some things to match tokens based on column names in database
db_analytes$analyte_name_clean <- gsub("Bulk Density","Bulk Density Db",db_analytes$analyte_name)
db_analytes$analyte_name_clean <- gsub("1/3","third thirdbar",db_analytes$analyte_name)
db_analytes$analyte_name_clean <- gsub("<","lt",db_analytes$analyte_name_clean)
db_analytes$analyte_name_clean <- gsub("1/10","tenth tenthbar",db_analytes$analyte_name_clean)

db_methods <- subset(methods, method_group == "Bulk Density")
db_methods$requested_anal_name_clean <- gsub("1/3","third thirdbar",db_methods$requested_anal_name)
db_methods$requested_anal_name_clean <- gsub("<","lt",db_methods$requested_anal_name_clean)
db_methods$requested_anal_name_clean <- gsub("1/10","tenth tenthbar",db_methods$requested_anal_name_clean)

# the DbWR1 method code is used for multiple moisture states
moisture_states <- db_methods[c(1:2,1:2),]
moisture_states$requested_anal_name_clean <- paste0(moisture_states$requested_anal_name_clean, rep(c(" third thirdbar", 
                                                                                                     " oven dry")))
db_methods <- rbind(moisture_states, db_methods[2:nrow(db_methods),])

tokens <- lapply(lapply(db_measur_cols, strsplit, "_"), function(x) x[[1]])
matching_analytes <- lapply(lapply(tokens, function(mtokens) {
    res <- lapply(mtokens, function(token) {
      grepl(token, db_analytes$analyte_name_clean, ignore.case = TRUE)
    })
    return(res)
  }), function(x) {
    y <- rowSums(do.call('cbind', x))
    db_analytes[which(y == max(y)),]
  })
good_analytes <- do.call('rbind', lapply(1:length(matching_analytes), function(z) { 
    if(nrow(matching_analytes[[z]])) {
      matching_analytes[[z]]$name <- db_measur_cols[z] 
      matching_analytes[[z]]$aid <- 1:nrow(matching_analytes[[z]])
      matching_analytes[[z]]
    }
  }))
# take first and most specific column name from analyte table only
best_analytes <- do.call('rbind', lapply(split(good_analytes, good_analytes$analyte_name_clean), function(x) {
    return(x[which(nchar(x$name) == max(nchar(x$name)))[1],])
  }))

# TODO: abstract this beast
matching_methods <- lapply(lapply(tokens, function(mtokens) {
  res <- lapply(mtokens, function(token) {
    grepl(token, db_methods$requested_anal_name_clean, ignore.case = TRUE)
  })
  return(res)
}), function(x) {
  y <- rowSums(do.call('cbind', x))
  db_methods[which(y == max(y)),]
})
db_data_methods_num <- db_data_methods
names(db_data_methods_num) <- NULL
best_methods <- do.call('rbind', lapply(1:length(matching_methods), function(z) { 
  matching_methods[[z]] <- subset(matching_methods[[z]], proced_code %in% db_data_methods_num[[z]])
  if (nrow(matching_methods[[z]])) {
     matching_methods[[z]]$name <- db_measur_cols[z] 
     matching_methods[[z]]$mid <- 1:nrow(matching_methods[[z]])
     matching_methods[[z]]
  }
}))

# 25 different analytes (method classes) in NCSS characterization database contain prefix db_
# they all pertain to bulk density
# nrow(db_analytes)

db_analytes2 <- merge(best_analytes, best_methods)[,c("analyte_type", "aid", "analyte_abbrev", "mid", "proced_code")]
db_analytes_unpaired <- db_analytes[!(db_analytes$analyte_abbrev %in% db_analytes2$analyte_abbrev), c("analyte_type", "analyte_abbrev")]
db_analytes_unpaired$aid <- 1
db_analytes_unpaired$mid <- 1
db_analytes_unpaired$proced_code <- "No method code"
db_analytes_unpaired$proced_code[grepl("aggregate", db_analytes_unpaired$analyte_type)] <- "Not in snapshot?"
db_analytes2 <- rbind(db_analytes2, db_analytes_unpaired)
```

```{r, fig.width=10, fig.height=10, echo=FALSE}
set.seed(544)
db_analytes2$pathString <- paste("NCSSC_BulkDensity", 
                            db_analytes2$analyte_type, 
                            db_analytes2$analyte_abbrev, 
                            db_analytes2$proced_code,
                            sep = "/")
library(networkD3)
par(mar = c(0,0,0,0))
useRtreeList <- ToListExplicit(as.Node(db_analytes2), unname = TRUE)
radialNetwork(useRtreeList, fontSize = 18)
```

```{r, fig.width=10, fig.height=10, echo=FALSE}
res <- lapply(analytes$analyte_abbrev, grepl, analytes$analyte_algorithm)
analyte.sub <- analytes[do.call('c', lapply(res, which)),]
analyte.sub$analyte_size_frac_base[is.na(analyte.sub$analyte_size_frac_base)] <- "NONE"

analyte.sub$pathString <- paste("NCSSC_analytes", 
                                 analyte.sub$analyte_type, 
                                 analyte.sub$analyte_size_frac_base,
                                 analyte.sub$analyte_abbrev,
                                 sep = "/")
analyte.sub <- as.Node(analyte.sub)

par(mar=c(0,0,0,0))
useRtreeList <- ToListExplicit(analyte.sub, unname = TRUE)
radialNetwork(useRtreeList, fontSize = 18)
```

Assumptions in derived values need to be made clear up front. Some commonly used measurements -- relating to saturation, "field capacity" and 15 bar moisture are actually _derived_ from other measurements. 

It is possible with well-correlated data to estimate conversions between different bases, given other soil properties. This is something we do routinely in NASIS. If this is a goal, it is absolutely critical that primary data with the relevant metadata get allocated _near as possible_ to their "correct" method. 

Whether using measured values or otherwise, a person using data in a meta-analysis may want to be able to use their own assumptions, or at least validate our assumptions. A broader, more "comprehensive" set of method codes could uniquely identify major variants of methods that may be encountered "in the wild" to further enhance interoperability.

```{r, echo=FALSE}
knitr::kable(db_analytes[,c("analyte_name","analyte_abbrev","analyte_type")],
             caption = 'NCSSC Bulk Density Analyte Name, Abbreviations and Types', row.names = FALSE)
```

Bulk density _measurements_ are composited into what we call an _aggregate_ analyte. The `analyte_type` column distinguishes these records from records that are _derived_ from other analytes.

Each one of the aggregate analytes types may have records for several specific method codes. For the KSSL's use of these databases internally, this mechanism has been employed to accomodate both external methods, as well as obsolesence of internal methods. 

From a bare-minimum data quality standpoint users of the NCSS Characterization database want to make sure they are not causing duplication by method codes that should be mutually exclusive; e.g. combining measurements of oven dry bulk density with 1/3 bar for same `labsampnum`.

"Aggregate" means we make repeated measures on subsamples to assess precision and accuracy for individual samples (`labsampnum`, layers or horizons in a soil profile), and a summary function is applied to yield the final value. For a soil property as fundamental and variable as bulk density, this is a pretty important thing to do for quality control. The measurements are prone to error, so sometimes it is important to have a sanity check.

```{r}
# NB: fix the space v.s. underscore in database analyte_type == "derived_analyte" and dupe of aggregate analyte
db_analytes_agg <- subset(db_analytes, analyte_type == "aggregate analyte" | analyte_type == "aggregate_analyte")
analytes_der <- subset(analytes, analyte_type == "derived_analyte")
```

So, if bulk density is so important, how can we show this? The `analyte_algorithm` contains an expression that can be evaluated to calculate a _derived_ analyte from other analytes. We will search that field to find dependencies.

```{R}
# calculate derived analytes that depend on the aggregate analytes
db_analytes_agg_idx <- lapply(db_analytes_agg$analyte_abbrev, 
                              function(i) { grep(i, analytes_der$analyte_algorithm) })
names(db_analytes_agg_idx) <- db_analytes_agg$analyte_name
```

Most bulk density methods in use for soil science should fall into one of the following aggregate analyte "classes," where they will either conform with an existing SSL method code, or may warrant a new one:

```{r, echo=FALSE}
knitr::kable(data.frame(analyte_name = sort(db_analytes_agg$analyte_name)))
```

### Where are the bulk density _aggregate_ analyte codes used in _derived_ analyte calculations?

```{r, results='asis', echo=FALSE}
for (y in rev(seq_along(db_analytes_agg_idx))) {
   y.n <- names(db_analytes_agg_idx)[y]
   y.idx <- db_analytes_agg_idx[[y.n]]
   dat <- analytes_der[y.idx, "analyte_name"]
   if (length(dat) == 0) {
     dat <- data.frame(NA)
   } else { 
     dat <- as.data.frame(dat)
   }
   colnames(dat) <- "Derived Analyte"
   print(knitr::kable(dat, caption = y.n, row.names = FALSE, escape = FALSE))
}
```

OK, we see that most of these methods are not used as inputs to derived analytes, but the first two (_`r paste0(head( rev(names(db_analytes_agg_idx)), 2), collapse = ", ")`_) have many dependencies. Let's compare the data we have, before going down a rabbit hole on all of these methods. 

First, we build some comparable datasets; we take the "long format" table subsets queried from `lab_physical_properties ` and merge so we have records that are 1:1 with `labsampnum`. Query 0.33 kPa and oven-dry data, ignoring specific method codes within classes.

```{r, echo=TRUE}
# note there is a 100,000 record and 32 Mb JSON serialization limit with SDA_query()
db13b <- SDA_query("SELECT labsampnum, result_source_key, 
                           bulk_density_third_bar, bulk_density_third_bar_method
                    FROM lab_physical_properties 
                    WHERE bulk_density_third_bar_method != ''")

dbod <- SDA_query("SELECT labsampnum, result_source_key, 
                          bulk_density_oven_dry, bulk_density_oven_dry_method
                    FROM lab_physical_properties 
                    WHERE bulk_density_oven_dry_method != ''")
```

```{r}
# inner join based on common attributes (labsampnum [and result_source_key])
dbcb <- merge(db13b, dbod)
```

We find we have 6 methods associated with different types of 0.33 kPa bulk density. Two methods (`4A1d` and `DbWR1`) are used for 0.33 kPa; the latter methods (`4A1e`and `4A1f` and `NK`, and `4A1c`) are variants not defined in the most recent SSL methods manual. 

```{r, echo=FALSE}
knitr::kable(table(dbcb$bulk_density_third_bar_method), col.names = c("Method","Count"), caption = "Third Bar Method")
```

For oven-dry, we have `4A1h` and `DbWR1`.

```{r, echo=FALSE}
knitr::kable(table(dbcb$bulk_density_oven_dry_method), col.names = c("Method","Count"), caption = "Oven Dry Method")
```

Most of the derived calculations use the Bulk Density at 1/3 bar (33 kPa), and some use oven dry. We will pull from the non-`DbWR1` methods first.

NOTE: Method code `4A1d` is obsolete code for _Bulk Density at 1/3 bar (33 kPa)_ moisture retention; now `3B1b.` `4A1h` is obsolete code for _Oven-dry Bulk Density_; now `3B1c`.

```{r}
dbcb_comparable1 <- subset(dbcb, bulk_density_third_bar_method %in% c("4A1d","3B1b") &
                                 bulk_density_oven_dry_method  %in% c("4A1h","3B1c"))
dbcb_comparable1 <- dbcb_comparable1[complete.cases(dbcb_comparable1),]

knitr::kable(table(dbcb_comparable1$bulk_density_third_bar_method), col.names = c("Method","Count"), caption = "Third Bar Method")
knitr::kable(table(dbcb_comparable1$bulk_density_oven_dry_method), col.names = c("Method","Count"), caption = "Oven Dry Method")
```

```{r, echo=FALSE}
ggplot(data = dbcb_comparable1, aes(x = bulk_density_third_bar, y = bulk_density_oven_dry)) + 
  geom_bin2d(bins = 50) + geom_abline(slope = 1, intercept = 0, colour = "red", lwd = 1) +
  labs(title = "Oven-dry (4A1h) versus 0.33 kPa Bulk Density (4A1d)",
       x = "Bulk Density, Oven-dry [g/cc]",
       y = "Bulk Density, 0.33 kPa moisture tension [g/cc]") +
  geom_text(aes(x = 2, y = 0.5, label = sprintf("n = %s (paired)", nrow(dbcb_comparable1)))) + 
  coord_fixed() +  expand_limits(x = c(0,3), y = c(0,3))

# increase in bulk density on oven-drying 
ggplot(data = dbcb_comparable1, aes(x = bulk_density_oven_dry - bulk_density_third_bar)) + 
  geom_density() +
  labs(title = "Increase in Bulk Density on Oven-drying (4A1h versus 4A1d)",    
       y = "Probability Density [-]",
       x = "Bulk Density, increase on drying [g/cc]") +
  geom_text(aes(x = 1, y = 1, label = sprintf("n = %s", nrow(dbcb_comparable1))))
```

Also, we will compare the `DbWR1` bulk density measures...

```{r}
dbcb_comparable2 <- subset(dbcb, bulk_density_third_bar_method == "DbWR1" &
                                 bulk_density_oven_dry_method == "DbWR1")
dbcb_comparable2 <- dbcb_comparable2[complete.cases(dbcb_comparable2),]

knitr::kable(table(dbcb_comparable2$bulk_density_third_bar_method), col.names = c("Method","Count"), caption = "Third Bar Method")
knitr::kable(table(dbcb_comparable2$bulk_density_oven_dry_method), col.names = c("Method","Count"), caption = "Oven Dry Method")
```

```{r, echo=FALSE}
ggplot(data = dbcb_comparable2, aes(x = bulk_density_third_bar, y = bulk_density_oven_dry)) + 
  geom_bin2d(bins = 50) + geom_abline(slope = 1, intercept = 0, colour = "red", lwd = 1) +
  labs(title = "Oven-dry versus 0.33 kPa Bulk Density (DbWR1)",
       x = "Bulk Density, Oven-dry [g/cc]",
       y = "Bulk Density, 0.33 kPa moisture tension [g/cc]") + 
  geom_text(aes(x = 2, y = 1, label = sprintf("n = %s (paired)", nrow(dbcb_comparable2)))) + 
  coord_fixed() +  expand_limits(x = c(0, 5), y = c(0, 5))

# increase in bulk density on oven-drying 
ggplot(data = dbcb_comparable2, aes(x = bulk_density_oven_dry - bulk_density_third_bar)) + 
  geom_density() +
  labs(title = "Increase in Bulk Density on Oven-drying (DbWR1)",    
       y = "Probability Density [-]",
       x = "Bulk Density, increase on drying [g/cc]") +
  geom_text(aes(x = 1, y = 1, label = sprintf("n = %s", nrow(dbcb_comparable2))))
```

Finally, these mixed-method samples have `DbWR1` for their `third_bar` method and `4A1h` for their oven-dry.

```{r}
dbcb_mixed <- subset(dbcb, bulk_density_third_bar_method == "DbWR1" &
                           bulk_density_oven_dry_method == "4A1h")
knitr::kable(table(dbcb_mixed$bulk_density_third_bar_method), col.names = c("Method","Count"), caption = "Third Bar Method")
knitr::kable(table(dbcb_mixed$bulk_density_oven_dry_method), col.names = c("Method","Count"), caption = "Oven Dry Method")
```

```{r, echo=FALSE}
ggplot(data = dbcb_mixed, aes(x = bulk_density_third_bar, y = bulk_density_oven_dry)) + 
  geom_bin2d(bins = 50) + geom_abline(slope = 1, intercept = 0, colour = "red", lwd = 1) +
  labs(title = "Oven-dry versus 0.33 kPa Bulk Density\n(mixed 4A1h oven dry; DbWR1 0.33 kPa)",
       x = "Bulk Density, Oven-dry [g/cc]",
       y = "Bulk Density, 0.33 kPa moisture tension [g/cc]") + 
  geom_text(aes(x = 2, y = 0.5, label = sprintf("n = %s (paired)", nrow(dbcb_mixed)))) + 
  coord_fixed() +  expand_limits(x = c(0, 3), y = c(0, 3))

# increase in bulk density on oven-drying 
ggplot(data = dbcb_mixed, aes(x = bulk_density_oven_dry - bulk_density_third_bar)) + 
  geom_density() +
  labs(title = "Increase in Bulk Density on Oven-drying\n(mixed 4A1h oven dry; DbWR1 0.33 kPa)",    
       y = "Probability Density [-]",
       x = "Bulk Density, increase on drying [g/cc]") +
  geom_text(aes(x = 0.5, y = 1, label = sprintf("n = %s", nrow(dbcb_mixed))))
```

Tabulate results to go with the graphs:

```{r}
# summary statistics reveal similar offsets and distribution of Db increase on oven drying
do_diff <- function(x) {
  difff <- with(x, bulk_density_oven_dry - bulk_density_third_bar)
  print(knitr::kable(data.frame(Q = t(quantile(difff, probs = c(0,0.01,0.05,0.5,0.95,0.99,1))), mean(difff), sd(difff)),
                     col.names = c("Q0", "Q1", "Q5", "Q50", "Q95", "Q99", "Q100", "MEAN", "SD"), digits = 2))
}

do_diff(dbcb_comparable1)

do_diff(dbcb_comparable2)

do_diff(dbcb_mixed)
```

In total, we have `r nrow(dbcb_comparable1) + nrow(dbcb_comparable2)` measurements between the paired sets

```{r}
any(dbcb_comparable1$labsampnum %in% dbcb_comparable2$labsampnum)
nrow(dbcb_comparable1) + nrow(dbcb_comparable2) 
```


### Conclusion

Bulk density integrates many aspects of the soil fabric. Bulk density is describing how the soil "body" occupies space. Our measurement of bulk density is highly affected by the tools we use to extract a sample or measure the volume of a particular portion of soil material. It is also affected by whether (and to what degree) we consider water and/or rock fragments to be soil materials. This is discipline and region specific.

#### Applied Example

In the realm of carbon stocks, for instance, bulk density is a property to consider carefully. Given measured organic carbon contents in, say, grams per kilogram across depth [soil materials change over depth] your choice as an analyst of the soil bulk density-depth function _matters_ to the estimate of the carbon stocks ($kg/m^2$) over a depth interval. 

The relevance of bulk density to carbon stocks can be seen in the classification of the Humults in U.S. Soil Taxonomy.

**Here is an excerpt from the Ultisols suborder key:**

**HB.** Other Ultisols that have _one or both_ of the following:

1. 0.9 percent (by weighted average) or more organic carbon in the upper 15 cm of the argillic or kandic horizon; or

2. $12 kg/m^2$ or more organic carbon between the mineral soil surface and a depth of 100 cm.'

You will notice that criterion #1 is a carbon mass-percent weighted average, and criterion #2 is a carbon stock. See the Humults criteria demo for an exploration of soil carbon related taxonomic criteria in the _Humults_
   
 - [_Humults_ criteria example](humults.html)

### References

U.S. Department of Agriculture, Natural Resources Conservation Service. National Soil Survey Handbook (NSSH), title 430-VI. <http://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/ref/?cid=nrcs142p2_054242> (accessed 06 November 2020).

Soil Survey Staff. 2014. Keys to Soil Taxonomy, 12th ed. USDA-Natural Resources Conservation Service, Washington, DC.
<https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/survey/class/taxonomy/?cid=nrcs142p2_053580>.
